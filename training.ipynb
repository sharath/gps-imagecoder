{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time as T\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.encoding import poisson\n",
    "from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.preprocessing import NumentaPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('logs')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logs(start_time,name, msg):\n",
    "    lfname = f'logs/{start_time}_{os.path.basename(name)[:-4]}_spikes.csv'\n",
    "    with open(lfname, 'a') as f:\n",
    "        f.write(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = './dataset/'\n",
    "encpath = './encoding/'\n",
    "datafiles = [os.path.join(datapath, x) for x in os.listdir(datapath)]\n",
    "encfiles = [os.path.join(encpath, x[:-4])+'.enc' for x in os.listdir(datapath)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = NumentaPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = [enc.process(csvfile=d, use_cache=True, cachedfile=e)\n",
    "             for d, e in zip(datafiles, encfiles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklist = sorted(zip(encfiles, encodings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 500\n",
    "network = DiehlAndCook2015(5000, dt=1.0, norm=48.95, inh=3)\n",
    "exc_monitor = Monitor(network.layers['Ae'], ['v', 's'], time=time)\n",
    "network.add_monitor(exc_monitor, name='exc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relax(network, time=50):\n",
    "    img = torch.zeros(5000)\n",
    "    inpts = {'X': poisson(img, time)}\n",
    "    network.run(inpts=inpts, time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track track01   Iteration 137\n"
     ]
    }
   ],
   "source": [
    "start = int(T.time())\n",
    "for name, track in tracklist:\n",
    "    logs(start, name, 'Iteration,Neuron,Spikes\\n')\n",
    "    for i in range(4, len(track)):\n",
    "        print(f'Track {os.path.basename(name)[:-4]}   Iteration {i-3}')\n",
    "        orig = 255*torch.cat((track[i-4], track[i-3], track[i-2], track[i-1], track[i]))\n",
    "        pt = poisson(orig, time)\n",
    "        \n",
    "        inpts = {'X': pt}\n",
    "        network.run(inpts=inpts, time=time)\n",
    "        relax(network)\n",
    "        \n",
    "        spikes = exc_monitor.get('s')\n",
    "        voltage = exc_monitor.get('v')\n",
    "        \n",
    "        for neuron, value in enumerate(torch.sum(spikes, dim=1)):\n",
    "            logs(start, name, f'{i-4},{neuron},{int(value)}\\n')\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "network.save(f'trained_{start}.net')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
